---
title: "Ollama Models"
description: "Learn how to configure ollama models in RabbitHoles."
icon: "code"
---

## Step 1 : Open your RabbitHoles app and navigate to ‚ÄúAI Settings‚Äù

![Screenshot 2025-01-16 at 9.50.00‚ÄØPM.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/953b4c50-29ab-4fca-aedf-c589f07d5485/65d3ef39-536f-4dce-a9da-d1a19a4991a5/Screenshot_2025-01-16_at_9.50.00_PM.png)

## Step 2 : Click on ollama under Model settings

![Screenshot 2025-01-19 at 8.54.24‚ÄØAM.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/953b4c50-29ab-4fca-aedf-c589f07d5485/8e6ea519-2955-46ca-ada9-c58fcc43f543/8da0b0ea-87b2-41f6-a1f6-231052e79e64.png)

- To get your model ID running, follow the below steps

## Step 3 : Setting up Ollama

1. Open your web browser and go to [Ollama URL](https://www.ollama.com/).
2. Click on the **"Sign In"** button at the top-right corner.

![Screenshot 2025-01-19 at 6.30.36‚ÄØPM.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/953b4c50-29ab-4fca-aedf-c589f07d5485/d83f3e34-c290-4235-8482-3d826b446b30/Screenshot_2025-01-19_at_6.30.36_PM.png)

- Enter your login credentials (email and password) or sign in using your preferred authentication method.
- Create an account if you don‚Äôt have one.

![Screenshot 2025-01-19 at 6.51.49‚ÄØPM.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/953b4c50-29ab-4fca-aedf-c589f07d5485/0c21ffb2-f732-4be3-8f71-4e468b0c2f0f/Screenshot_2025-01-19_at_6.51.49_PM.png)

- Once logged in, you will be redirected to your Ollama dashboard.

### Step 4: Download the Model for Your OS

#### For macOS

- Open Terminal (`Cmd + Space` ‚Üí Type **Terminal** ‚Üí Press **Enter**).
- Run the following command to install Ollama:

```bash
ollama pull {model_id}
Eg: ollama pull llama3.2
```

![Screenshot 2025-01-19 at 6.52.44‚ÄØPM.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/953b4c50-29ab-4fca-aedf-c589f07d5485/e2c320ca-a50f-469c-b098-67c9614f4d8f/6fd924a7-1c47-4d48-813e-8eb66df4e59f.png)

- Restart your terminal to apply changes.

#### **For Windows**

1. Download the installer from Ollama's website.
2. Run the installer and follow the on-screen instructions.
3. Open **Command Prompt** (`Win + R`, type `cmd`, and press **Enter**).

#### **For Linux**

1. Open Terminal.
2. Run the following command:
    
    ```bash
    curl -fsSL https://ollama.com/install.sh | sh
    ```
    
3. Restart your terminal after installation.

## **Step 5: Run the Models**

After installing Ollama, open your terminal or command prompt and run:

```bash
ollama run llama3.2
```

or

```bash
ollama run mistral
```

This will start the model and verify that it is running correctly.

## **Step 6: Integrate with Rabbitholes**

1. Open **Rabbitholes** and navigate to the **Ollama** integration window.
    
    ![Screenshot 2025-01-19 at 6.54.38‚ÄØPM.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/953b4c50-29ab-4fca-aedf-c589f07d5485/e6eab0fa-5bb7-480c-843f-194f41327b3d/Screenshot_2025-01-19_at_6.54.38_PM.png)
    
2. Under **Model ID**, add:
    - `llama3.2`
    - `mistral`
3. Save your settings, and you‚Äôre ready to use these models within Rabbitholes.

Now you can start running prompts with **Llama 3.2** and **Mistral** inside Rabbitholes! üöÄ
