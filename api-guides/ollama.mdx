---
title: "Ollama Models"
description: "Learn how to configure ollama models in RabbitHoles."
icon: "code"
---

## Step 1 : Open your RabbitHoles app and navigate to ‚ÄúAI Settings‚Äù

<img
  style={{ borderRadius: '0.5rem' }}
  src="/images/llama1.png"
/>
## Step 2 : Click on ollama under Model settings

<img
  style={{ borderRadius: '0.5rem' }}
  src="/images/llama2.png"
/>
- To get your model ID running, follow the below steps

## Step 3 : Setting up Ollama

1. Open your web browser and go to [Ollama URL](https://www.ollama.com/).
2. Click on the **"Sign In"** button at the top-right corner.

<img
  style={{ borderRadius: '0.5rem' }}
  src="/images/llama3.png"
/>
- Enter your login credentials (email and password) or sign in using your preferred authentication method.
- Create an account if you don‚Äôt have one.

<img
  style={{ borderRadius: '0.5rem' }}
  src="/images/llama4.png"
/>
- Once logged in, you will be redirected to your Ollama dashboard.

## Step 4: Download the Model for Your OS

#### For macOS

- Open Terminal (`Cmd + Space` ‚Üí Type **Terminal** ‚Üí Press **Enter**).
- Run the following command to install Ollama:

```bash
ollama pull {model_id}
Eg: ollama pull llama3.2
```

<img
  style={{ borderRadius: '0.5rem' }}
  src="/images/llama5.png"
/>
- Restart your terminal to apply changes.

#### **For Windows**

1. Download the installer from Ollama's website.
2. Run the installer and follow the on-screen instructions.
3. Open **Command Prompt** (`Win + R`, type `cmd`, and press **Enter**).

#### **For Linux**

1. Open Terminal.
2. Run the following command:
    
    ```bash
    curl -fsSL https://ollama.com/install.sh | sh
    ```
    
3. Restart your terminal after installation.

## **Step 5: Run the Models**

After installing Ollama, open your terminal or command prompt and run:

```bash
ollama run llama3.2
```

or

```bash
ollama run mistral
```

This will start the model and verify that it is running correctly.

## **Step 6: Integrate with Rabbitholes**

1. Open **Rabbitholes** and navigate to the **Ollama** integration window.
    
<img
  style={{ borderRadius: '0.5rem' }}
  src="/images/llama6.png"
/>    
2. Under **Model ID**, add:
    - `llama3.2`
    - `mistral`
3. Save your settings, and you‚Äôre ready to use these models within Rabbitholes.

Now you can start running prompts with **Llama 3.2** and **Mistral** inside Rabbitholes! üöÄ
